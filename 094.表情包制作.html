<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./assets/global.css">

    <style>
        #face {
            position: absolute;
        }
    </style>
</head>

<body>
    <canvas id="emo"></canvas>
    <canvas id="face"></canvas>

    <script src="./assets/face-api/face-api.min.js"></script>
    <script type="module">
        import "https://gcore.jsdelivr.net/npm/@3r/canvas-plus@1.0.8/index.js";

        /**
         * 靠近一点点
         * @author 	 linyisonger
         * @date 	 2025-03-24
         * @param {{x:number,y:number}} p
         * @param {{x:number,y:number}} t
         * @param {number} v
         */
        function zoom(p, t, v) {
            let tmpX = p.x - t.x;
            let tmpY = p.y - t.y;

            tmpX *= v;
            tmpY *= v;

            return {
                x: t.x + tmpX,
                y: t.y + tmpY,
            }
        }


        /**
         * 加载图
         * @param {string} src
         * @returns {Promise<HTMLImageElement>}
         */
        function loadImage(src) {
            return new Promise((resolve) => {
                let image = new Image()
                image.src = src;
                image.onload = (ev) => {
                    resolve(image)
                }
            })
        }


        /**
         * 绘制表情包的背景
         * @author 	 linyisonger
         * @date 	 2025-03-24
         */
        async function drawEmoBackground() {
            /** @type {HTMLCanvasElement} */
            let canvas = document.querySelector("#emo")
            let ctx = canvas.getContext('2d')
            let pandaHead = await loadImage('./assets/pandaHead.png')
            width = pandaHead.width;
            height = pandaHead.height;
            canvas.width = width;
            canvas.height = height;
            ctx.clearRect(0, 0, width, height)
            ctx.drawImage(pandaHead, 0, 0, width, height);
        }

        /**
         * 获取面部信息
         * @author 	 linyisonger
         * @date 	 2025-03-24
         */
        async function drawFaceImage(url) {
            const originImg = await faceapi.fetchImage(url) // 获取原图
            const detections = await faceapi.detectSingleFace(originImg).withFaceLandmarks() // 获取特征
            const positions = detections.landmarks.positions; // 面部坐标点位
            const linkPositionIndexList = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17] // 外轮廓
            const zoomPositionIndexList = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16] // 脸颊
            /** @type {HTMLCanvasElement} */
            let canvas = document.querySelector("#face")
            let ctx = canvas.getContext('2d')
            let width = originImg.width;
            let height = originImg.height;
            canvas.width = width;
            canvas.height = height;

            for (let i = 0; i < zoomPositionIndexList.length; i++) {
                const zoomPosition = positions[zoomPositionIndexList[i]];
                positions[zoomPositionIndexList[i]] = zoom(zoomPosition, positions[29], .8) // 缩放脸颊 清除黑边
            }

            // 裁切操作
            ctx.beginPath();
            ctx.strokeStyle = '#000'
            ctx.lineWidth = 2;
            for (let i = 0; i < linkPositionIndexList.length; i++) {
                const linkPosition = positions[linkPositionIndexList[i]];
                i == 0 ? ctx.moveTo(linkPosition.x, linkPosition.y) : ctx.lineTo(linkPosition.x, linkPosition.y)
            }
            ctx.closePath();
            ctx.clip();
            ctx.drawImage(originImg, 0, 0, width, height); // 渲染原图 
            ctx.grayProcessing({}) // 灰度处理
            let layerSizeRes = ctx.layerSize({}) // 获取尺寸
            faceImageData = ctx.getImageData(layerSizeRes.x, layerSizeRes.y, layerSizeRes.w, layerSizeRes.h)
            ctx.clearRect(0, 0, width, height)
            width = layerSizeRes.w;
            height = layerSizeRes.h;
            canvas.width = width
            canvas.height = height
            ctx.putImageData(faceImageData, 0, 0)
        }

        async function drawFaceEffect() {
            /** @type {HTMLCanvasElement} */
            let canvas = document.querySelector("#face")
            let ctx = canvas.getContext('2d')
            ctx.clearRect(0, 0, canvas.width, canvas.height)
            ctx.putImageData(faceImageData, 0, 0)
            ctx.luminance({ v: -.5 })
            ctx.exposure({ v: 4 })
            ctx.contrastRatio({ v: 2 })
        }


        Promise.all([
            faceapi.nets.faceRecognitionNet.loadFromUri('./assets/face-api/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('./assets/face-api/models'),
            faceapi.nets.ssdMobilenetv1.loadFromUri('./assets/face-api/models')
        ]).then(start)

        let faceImageData = null

        async function start() {
            // drawEmoBackground()
            await drawFaceImage('./assets/stars/bailu.jpg')
            drawFaceEffect()
        }
    </script>




</body>

</html>